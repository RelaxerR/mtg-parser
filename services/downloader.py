"""–°–µ—Ä–≤–∏—Å –∑–∞–≥—Ä—É–∑–∫–∏ –∫–∞—Ä—Ç —Å Scryfall —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""

import time
import requests
from pathlib import Path
from typing import Optional, List, Tuple
from tqdm import tqdm
from config import SCRYFALL_RANDOM_URL, REQUEST_DELAY, REQUEST_TIMEOUT, DIR_HTML_CACHE


class CardDownloader:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–µ –∫–∞—Ä—Ç—ã —Å Scryfall –∏ –∫—ç—à–∏—Ä—É–µ—Ç HTML.
    
    Attributes:
        cache_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è HTML-—Ñ–∞–π–ª–æ–≤.
        delay: –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (–∑–∞—â–∏—Ç–∞ –æ—Ç rate-limit).
    """
    
    def __init__(self, cache_dir: Path = DIR_HTML_CACHE, delay: float = REQUEST_DELAY):
        self.cache_dir = cache_dir
        self.delay = delay
        self.cache_dir.mkdir(parents=True, exist_ok=True)
    
    def _save_to_cache(self, html: str, url: str) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç HTML-–∫–æ–Ω—Ç–µ–Ω—Ç –≤ –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª."""
        slug = url.rstrip('/').split('/')[-1]
        filepath = self.cache_dir / f"card_{slug}.html"
        filepath.write_text(html, encoding='utf-8')
    
    def fetch_one(self) -> Optional[Tuple[str, str]]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–¥–Ω—É —Å–ª—É—á–∞–π–Ω—É—é –∫–∞—Ä—Ç—É.
        
        Returns:
            Tuple(html_content, final_url) –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ.
        """
        try:
            response = requests.get(
                SCRYFALL_RANDOM_URL,
                allow_redirects=True,
                timeout=REQUEST_TIMEOUT
            )
            response.raise_for_status()
            
            self._save_to_cache(response.text, response.url)
            return response.text, response.url
            
        except requests.RequestException as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            return None
    
    def fetch_batch(self, count: int) -> List[Tuple[str, str]]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–∞–∫–µ—Ç –∫–∞—Ä—Ç —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º.
        
        Args:
            count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Ä—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏.
            
        Returns:
            List[Tuple]: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (html_content, url).
        """
        results = []
        
        with tqdm(
            total=count,
            desc="üì• –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ä—Ç",
            unit="–∫–∞—Ä—Ç–∞",
            colour="green",
            ncols=80
        ) as pbar:
            for i in range(count):
                card = self.fetch_one()
                
                if card:
                    results.append(card)
                    pbar.set_postfix({"‚úÖ": len(results), "‚ùå": i + 1 - len(results)})
                    pbar.update(1)
                else:
                    pbar.set_postfix({"‚úÖ": len(results), "‚ùå": i + 1 - len(results)})
                    pbar.update(1)
                
                time.sleep(self.delay)
        
        return results
    
    def load_from_cache(self, limit: Optional[int] = None) -> List[Tuple[str, str]]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–∞—Ä—Ç—ã –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫—ç—à–∞ HTML.
        
        Args:
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Ä—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ (None = –≤—Å–µ).
            
        Returns:
            List[Tuple]: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (html_content, url).
        """
        html_files = sorted(self.cache_dir.glob("card_*.html"))
        
        if not html_files:
            print("‚ö†Ô∏è –ö—ç—à –ø—É—Å—Ç ‚Äî –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü.")
            return []
        
        if limit:
            html_files = html_files[:limit]
        
        results = []
        print(f"üìÇ –ù–∞–π–¥–µ–Ω–æ {len(html_files)} —Ñ–∞–π–ª–æ–≤ –≤ –∫—ç—à–µ")
        
        with tqdm(
            total=len(html_files),
            desc="üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ –∫—ç—à–∞",
            unit="—Ñ–∞–π–ª",
            colour="cyan",
            ncols=80
        ) as pbar:
            for filepath in html_files:
                try:
                    html_content = filepath.read_text(encoding='utf-8')
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º URL –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                    slug = filepath.stem.replace("card_", "")
                    url = f"https://scryfall.com/card/{slug}"
                    results.append((html_content, url))
                    pbar.update(1)
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {filepath.name}: {e}")
                    pbar.update(1)
        
        return results
    
    def get_cache_count(self) -> int:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –≤ –∫—ç—à–µ."""
        return len(list(self.cache_dir.glob("card_*.html")))
    
    def clear_cache(self) -> int:
        """
        –û—á–∏—â–∞–µ—Ç –∫—ç—à HTML-—Ñ–∞–π–ª–æ–≤.
        
        Returns:
            int: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤.
        """
        html_files = list(self.cache_dir.glob("card_*.html"))
        for filepath in html_files:
            filepath.unlink()
        return len(html_files)